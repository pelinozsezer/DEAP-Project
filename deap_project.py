# -*- coding: utf-8 -*-
"""DEAP_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D1Hde9ri9cuyCL1n_4FLEXQUxLfPbg01

**Project name: Decoding The Subjective Ratings of Valence From EEG Activation Evoked by Emotional Visual Stimuli**

**Dataset: [DEAP dataset](https://www.eecs.qmul.ac.uk/mmv/datasets/deap/)**

-------------

**Import libraries, packages, etc.**
"""

import matplotlib.pyplot as plt 
import pandas as pd
import numpy as np
import pickle
import os
import h5py
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
!pip install mne

"""# **Mounting the data**

**Mount the data from Pelin's Google Drive**
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# drive.mount("/content/drive", force_remount=True)
# %cd /content/drive/MyDrive/Education/Course & Content/Neuromatch Academy - Computational Neuroscience/DEAP Project
!ls

"""**OYKU's Drive**"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# drive.mount("/content/drive", force_remount=True)
# %cd /content/drive/MyDrive/DEAP Project
!ls

"""**YAGMUR's Drive**"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# drive.mount("/content/drive", force_remount=True)
# %cd /content/drive/MyDrive/Education/Course & Content/Neuromatch Academy - Computational Neuroscience/DEAP Project
!ls

"""**ZEYNEP's Drive**"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# drive.mount("/content/drive", force_remount=True)
# %cd /content/drive/MyDrive/DEAP_Dataset

"""# **MAIN**

## **Explore the data**

**Check if everything works fine**
"""

df = pd.read_csv('metadata_csv/participant_ratings.csv')
df

"""**Import .dat files into array** """

for i in [1, 3, 4, 5, 6, 7, 8, 9, 10, 11]:
  if i<10:
      f = ['s0' + str(i) + '.dat']
  else:
    f = ['s' + str(i) + '.dat']
  print(f)

"""**Test:** first 10 subjects"""

fname = "s01.dat","s02.dat", "s03.dat", "s04.dat", "s05.dat", "s06.dat", "s07.dat", "s08.dat", "s09.dat", "s10.dat"
fname

data = np.empty((10,40,40,8064))
data[:] = np.nan
data.shape

for i in np.arange(0, 10):
  print(fname[i])
  x = pickle.load(open(fname[i], "rb"), encoding="latin1")
  data[i] = x["data"]                                    # shape is (40, 40, 8064) i.e., (trials, channels, samples)

s1_data = data[1,:,:,:] # trial,channel,sample

f_sampling = 128
time = np.linspace(-3, 60, 63 * f_sampling)
time.shape

sub_data = s1_data[20, 15,: ]
plt.plot(time,sub_data)

"""# **CNN PART**

Check where you are, in which directory.
"""

# Print the current working directory
print("Current working directory: {0}".format(os.getcwd()))

f = h5py.File('deap_data_all.mat','r')
eeg = f.get('eeg_all')
eeg = np.array(eeg) # For converting to a NumPy array
val=f.get('valence_all')
val=np.array(val)
np.random.seed(1)

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(8064, 32, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.summary()

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(2))

model.summary()

class_names = ['low_val','high_val']
val=np.where(val > 4.5, 1, 0)

ind=np.arange(0,1280,1)
test_ind=np.random.choice(ind,size=256, replace=False)
eeg.shape

eeg_t=np.transpose(eeg,(2,0,1))
eeg_t.shape

val_t=np.transpose(val,(1,0))
val_t.shape

test_eeg = eeg_t[test_ind,:,:]
test_eeg.shape

test_val=val_t[test_ind,:]
test_val.shape

train_ind=np.setdiff1d(ind,test_ind)
train_ind.shape

train_eeg = eeg_t[train_ind,:,:]
train_eeg.shape

train_val = val_t[train_ind,:]
train_val.shape

"""**The most exciting part <3**

**Work out the model**
"""

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_eeg, train_val, epochs=10, 
                    validation_data=(test_eeg, test_val))

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(test_eeg,  test_val, verbose=2)

print(test_acc)